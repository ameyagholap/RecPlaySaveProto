<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>AudioWaveArt - Record your voice sample</title>
    <style type='text/css'>
        ul
        {
            list-style: none;
        }
        #recordingslist audio
        {
            display: block;
            margin-bottom: 10px;
        }
    </style>
</head>
<body style="font-family: Arial; padding: 20px">
    <h1>
        AudioWaveArt - Record your voice sample</h1>
    <p>
        Make sure you are using a recent version of Google Chrome.</p>
    <p>
        Before you enable microphone input either plug in headphones or turn the volume
        down if you want to avoid ear splitting feedback!</p>
    <p>
        If you think the generated audio wave is too noisy, adjust the microphone levels
        and boost settings in your windows audio device options. You may record your phrase
        as many times as you like and select the best wave of them all!
    </p>
    <h2>
        Record Wave</h2>
    <p>
        This is the ALPHA version of the code, eventually voice samples will be restricted
        to 30 seconds only. For now you may record as big a sample as you wish, but for
        sake of quicker processing and results, try shorter samples
    </p>
    <button onclick="startRecording(this);">
        START RECORDING</button>
    <button onclick="stopRecording(this);" disabled>
        STOP RECORDING</button>
    <h2>
        Your Recordings</h2>
    <p>
        The audio recordings will show up in a list as you record your voice samples
    </p>
    <ul id="recordingslist">
    </ul>
    <div id="canvasHolder">
    </div>
    <hr />
    <h4>
        Developer Log (for testing purposes only)</h4>
    <pre id="log"></pre>
    <script>
        function __log(e, data) {
            log.innerHTML += "\n" + e + " " + (data || '');
        }

        var audio_context;
        var recorder;

        function startUserMedia(stream) {
            var input = audio_context.createMediaStreamSource(stream);
            __log('Media stream created.');

            // Uncomment if you want the audio to feedback directly
            //input.connect(audio_context.destination);
            //__log('Input connected to audio context destination.');

            recorder = new Recorder(input);
            __log('Recorder initialised.');
        }

        function startRecording(button) {
            recorder && recorder.record();
            button.disabled = true;
            button.nextElementSibling.disabled = false;
            __log('Recording...');
        }

        function stopRecording(button) {
            recorder && recorder.stop();
            button.disabled = true;
            button.previousElementSibling.disabled = false;
            __log('Stopped recording.');

            // create WAV download link using audio data blob
            createDownloadLink();
        }

        function createDownloadLink() {
            __log('Creating download link..');
            recorder && recorder.exportWAV(exportWAVB, 'audio/mp3');
        }

        function exportWAVB(blob) {
            try {
                var url = URL.createObjectURL(blob);
                var li = document.createElement('li');
                var au = document.createElement('audio');
                var hf = document.createElement('a');

                au.controls = true;
                au.src = url;
                hf.href = url;
                hf.download = new Date().toISOString() + '.wav';
                hf.innerHTML = hf.download;
                li.appendChild(au);
                li.appendChild(hf);
                recordingslist.appendChild(li);
            }
            catch (e) {
            }
            __log('Creating download link..DONE');
            __log('Generating spectrogram..');
            recorder.getBuffer(inspectFloatArray);
            recorder.clear();
        }

        function inspectFloatArray(buffers) {
            try {
                if (buffers == null || buffers.length < 1) return;

                // code for playback
                // var newSource = audio_context.createBufferSource();
                // var newBuffer = audio_context.createBuffer(2, buffers[0].length, audio_context.sampleRate);
                // newBuffer.getChannelData(0).set(buffers[0]);
                // if (buffers.length > 1)
                //     newBuffer.getChannelData(1).set(buffers[1]);
                // newSource.buffer = newBuffer;
                // newSource.connect(audio_context.destination);
                // newSource.start(0);

                if (buffers.length > 0) {

                    var canvasHolder = document.getElementById('canvasHolder');
                    var canvasW = screen.availWidth - 200; //canvas.clientHeight;
                    var canvasH = 600; //canvas.clientHeight;
                    var singleXUnit = canvasW / buffers[0].length;

                    //__log('singleXUnit: ' + singleXUnit);
                    //__log('canvas height: ' + canvasH);

                    var svgCancas = "<svg id='canvas' style='height: " + canvasH + "px; width: " + canvasW + "px; border: solid 1px gray'>";

                    for (i = 0; i < buffers[0].length - 1; i++) {

                        //var line = document.createElement('line');
                        var x1 = i * singleXUnit;
                        var y1 = (1 - buffers[0][i]) * (canvasH / 2);
                        var x2 = (i + 1) * singleXUnit;
                        var y2 = (1 - buffers[0][i + 1]) * (canvasH / 2)

                        //line.setAttribute('x1', x1);
                        //line.setAttribute('y1', y1);
                        //line.setAttribute('x2', x2);
                        //line.setAttribute('y2', y2);
                        //line.setAttribute('style', 'stroke:rgb(255,0,0);stroke-width:1');

                        var line = "<line x1='" + x1 + "' y1='" + y1 + "' x2='" + x2 + "' y2='" + y2 + "' style='stroke:rgb(255,0,0);stroke-width:1'/>";

                        svgCancas = svgCancas + line;

                        //canvas.appendChild(line);
                    }

                    svgCancas = svgCancas + "</svg>";

                    canvasHolder.innerHTML = svgCancas;

                    __log('Generating spectrogram..DONE');
                }
            }
            catch (e) {
                alert(e);
            }
        }

        window.onload = function init() {
            try {
                // webkit shim
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
                window.URL = window.URL || window.webkitURL;

                audio_context = new AudioContext;
                __log('Audio context set up.');
                __log('navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'));
            } catch (e) {
                alert('No web audio support in this browser!');
            }

            navigator.getUserMedia({ audio: true }, startUserMedia, function (e) {
                __log('No live audio input: ' + e);
            });
        };
    </script>
    <script src="recorder.js"></script>
</body>
</html>
